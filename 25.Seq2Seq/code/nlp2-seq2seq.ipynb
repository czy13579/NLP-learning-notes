{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7964922,"sourceType":"datasetVersion","datasetId":4686007}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv('/kaggle/input/iwslt2017-en-zh/test.csv')\nen_list=df['en'].tolist()\nzh_list=df['zh'].tolist()\nen_list[:5],zh_list[:5],len(en_list)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:40:58.775710Z","iopub.execute_input":"2024-04-17T01:40:58.776627Z","iopub.status.idle":"2024-04-17T01:40:58.827392Z","shell.execute_reply.started":"2024-04-17T01:40:58.776591Z","shell.execute_reply":"2024-04-17T01:40:58.826337Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(['Several years ago here at TED, Peter Skillman  introduced a design challenge  called the marshmallow challenge.',\n  \"And the idea's pretty simple:  Teams of four have to build the tallest free-standing structure  out of 20 sticks of spaghetti,  one yard of tape, one yard of string  and a marshmallow.\",\n  'The marshmallow has to be on top.',\n  \"And, though it seems really simple, it's actually pretty hard  because it forces people  to collaborate very quickly.\",\n  'And so, I thought this was an interesting idea,  and I incorporated it into a design workshop.'],\n ['几年前，在TED大会上， Peter Skillman 介绍了一个设计挑战 叫做“棉花糖挑战”',\n  '是个非常简单的主意 要求一组四人的团队搭建一个独立的最高建筑 材料是20根意大利面条 一段胶带，一段绳子 一块棉花糖',\n  '棉花糖必须放在最上面',\n  '这虽然看似简单，其实并不容易 因为它要求人们 迅速地合作',\n  '我觉得这是个有趣的主意 我把它放到了设计专题讨论会上'],\n 8549)"},"metadata":{}}]},{"cell_type":"code","source":"en_zh=[]\nfor en,zh in zip(en_list,zh_list):\n    new_en=[]\n    for word in en.split(' '):\n        word=word.replace('.', '').replace(',','').lower()\n        if word:\n            new_en.append(word)\n    en_zh.append((new_en,list(zh)))\n\nprint(en_zh[1])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:01.037213Z","iopub.execute_input":"2024-04-17T01:41:01.037638Z","iopub.status.idle":"2024-04-17T01:41:01.422503Z","shell.execute_reply.started":"2024-04-17T01:41:01.037595Z","shell.execute_reply":"2024-04-17T01:41:01.421348Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"(['and', 'the', \"idea's\", 'pretty', 'simple:', 'teams', 'of', 'four', 'have', 'to', 'build', 'the', 'tallest', 'free-standing', 'structure', 'out', 'of', '20', 'sticks', 'of', 'spaghetti', 'one', 'yard', 'of', 'tape', 'one', 'yard', 'of', 'string', 'and', 'a', 'marshmallow'], ['是', '个', '非', '常', '简', '单', '的', '主', '意', ' ', '要', '求', '一', '组', '四', '人', '的', '团', '队', '搭', '建', '一', '个', '独', '立', '的', '最', '高', '建', '筑', ' ', '材', '料', '是', '2', '0', '根', '意', '大', '利', '面', '条', ' ', '一', '段', '胶', '带', '，', '一', '段', '绳', '子', ' ', '一', '块', '棉', '花', '糖'])\n","output_type":"stream"}]},{"cell_type":"code","source":"en_words=set()\nzh_words=set()\n\nfor s in en_zh:\n    for char in s[0]:\n        en_words.add(char)\n    for char in s[1]:\n        if char:\n            zh_words.add(char)\nlen(zh_words),len(en_words)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:03.816443Z","iopub.execute_input":"2024-04-17T01:41:03.816830Z","iopub.status.idle":"2024-04-17T01:41:03.935828Z","shell.execute_reply.started":"2024-04-17T01:41:03.816800Z","shell.execute_reply":"2024-04-17T01:41:03.934478Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(2999, 12632)"},"metadata":{}}]},{"cell_type":"code","source":"en_wl=['sos','eos','pad']+list(en_words)\nzh_wl=['sos','eso','pad']+list(zh_words)\n\npad_id=2\nen2id={}\nzh2id={}\n\nfor i,w in enumerate(en_wl):\n    en2id[w]=i\nfor i,w in enumerate(zh_wl):\n    zh2id[w]=i","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:05.805326Z","iopub.execute_input":"2024-04-17T01:41:05.806110Z","iopub.status.idle":"2024-04-17T01:41:05.821362Z","shell.execute_reply.started":"2024-04-17T01:41:05.806077Z","shell.execute_reply":"2024-04-17T01:41:05.820267Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import random\nrandom.shuffle(en_zh)\ndl=len(en_zh)\ntrain_set=en_zh[:int(dl*0.8)]\ntest_set=en_zh[int(dl*0.8):]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:08.219941Z","iopub.execute_input":"2024-04-17T01:41:08.220359Z","iopub.status.idle":"2024-04-17T01:41:08.234513Z","shell.execute_reply.started":"2024-04-17T01:41:08.220322Z","shell.execute_reply":"2024-04-17T01:41:08.233464Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import torch\nbatch_size=16\ndata_workers=8\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:09.756473Z","iopub.execute_input":"2024-04-17T01:41:09.757437Z","iopub.status.idle":"2024-04-17T01:41:09.761984Z","shell.execute_reply.started":"2024-04-17T01:41:09.757399Z","shell.execute_reply":"2024-04-17T01:41:09.760832Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class MyDataSet(torch.utils.data.Dataset):\n    def __init__(self,examples):\n        self.examples=examples\n    def __len__(self):\n        return len(self.examples)\n    def __getitem__(self,index):\n        en,zh=self.examples[index]\n        ## 获取句子长度\n        l1=len(en)\n        l2=len(zh)\n        \n        return en,l1,zh,l2,index","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:11.388217Z","iopub.execute_input":"2024-04-17T01:41:11.388600Z","iopub.status.idle":"2024-04-17T01:41:11.395499Z","shell.execute_reply.started":"2024-04-17T01:41:11.388572Z","shell.execute_reply":"2024-04-17T01:41:11.394353Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"## collate_fn：即用于collate的function，\n## 用于对一个batch数据进行规整\ndef the_collate_fn(batch):\n    batch_size=len(batch)\n    en_list=[]\n    zh_list=[]\n    en_maxlen=0\n    zh_maxlen=0\n    for b in batch:\n        en_maxlen=max(en_maxlen,b[1])\n        zh_maxlen=max(zh_maxlen,b[3])\n        \n    \n    for x in batch:\n        l=[0]\n        for i in range(en_maxlen):\n            if i<x[1]:\n                l.append(en2id[x[0][i]])\n            else:\n                l.append(pad_id)\n        l.append(1)\n        en_list.append(l)\n    \n    for x in batch:\n        l=[0]\n        for i in range(zh_maxlen):\n            if i<x[3]:\n                l.append(zh2id[x[2][i]])\n            else:\n                l.append(pad_id)\n        l.append(1)\n        zh_list.append(l)     \n    indexs =[b[4] for b in batch]\n    ## RNN将batch换到第二个维度\n    en_tensor=torch.LongTensor(en_list).swapaxes(0,1)\n    zh_tensor=torch.LongTensor(zh_list).swapaxes(0,1)   \n    return en_tensor,zh_tensor,indexs\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:13.277014Z","iopub.execute_input":"2024-04-17T01:41:13.277772Z","iopub.status.idle":"2024-04-17T01:41:13.293737Z","shell.execute_reply.started":"2024-04-17T01:41:13.277741Z","shell.execute_reply":"2024-04-17T01:41:13.292618Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_dataset=MyDataSet(train_set)\ntest_dataset=MyDataSet(test_set)\nprint(train_dataset.__getitem__(0))\ntrain_data_loader=torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=the_collate_fn\n)\n\ntest_data_loader=torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=the_collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:15.750952Z","iopub.execute_input":"2024-04-17T01:41:15.751632Z","iopub.status.idle":"2024-04-17T01:41:15.767963Z","shell.execute_reply.started":"2024-04-17T01:41:15.751599Z","shell.execute_reply":"2024-04-17T01:41:15.766761Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"(['now', 'this', 'is', 'a', 'direct', 'conflict', 'between', 'the', 'experiencing', 'self', 'and', 'the', 'remembering', 'self'], 14, ['现', '在', '这', '是', '经', '验', '自', '我', '和', '记', '忆', '自', '我'], 13, 0)\n","output_type":"stream"}]},{"cell_type":"code","source":"examples=iter(train_data_loader)\ntest=next(examples)\ntest[0].shape,test[1].shape,test[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:18.588599Z","iopub.execute_input":"2024-04-17T01:41:18.588982Z","iopub.status.idle":"2024-04-17T01:41:18.786154Z","shell.execute_reply.started":"2024-04-17T01:41:18.588953Z","shell.execute_reply":"2024-04-17T01:41:18.784694Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"(torch.Size([73, 16]),\n torch.Size([127, 16]),\n [1436,\n  5060,\n  4527,\n  2409,\n  3771,\n  5536,\n  4023,\n  6718,\n  3133,\n  4111,\n  24,\n  4619,\n  3404,\n  4363,\n  2427,\n  4040])"},"metadata":{}}]},{"cell_type":"code","source":"from torch import nn\nclass Encoder(nn.Module):\n    def __init__(self,input_dim,emb_dim,hid_dim,n_layers,dropout):\n        super().__init__()\n        self.hid_dim=hid_dim\n        self.n_layers=n_layers\n        self.embedding=nn.Embedding(input_dim,emb_dim)\n        self.rnn=nn.LSTM(emb_dim,hid_dim,n_layers,dropout=dropout)\n        self.dropout=nn.Dropout(dropout)\n    def forward(self,en_sentence):\n        ## en_sentence(sentence_len,batch_Size)\n        embedded=self.dropout(self.embedding(en_sentence))\n        ## embedded (len,batch_size,emb_dim)\n        outputs,(hidden,cell)=self.rnn(embedded)\n        ## outputs(sentence_len,batch_size,hid_dim) 最顶层RNN的隐状态\n        ## hidden(n_layers,batch_size,hid_dim)\n        ## cell(n_layers,batch_size,hid_dim)\n        return hidden,cell\n\nencoder=Encoder(1000,100,128,2,0.5)\ntest_input=torch.ones((15,8),dtype=torch.long)\nhidden,cell=encoder(test_input)\nprint(hidden.shape)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:21.200379Z","iopub.execute_input":"2024-04-17T01:41:21.201480Z","iopub.status.idle":"2024-04-17T01:41:21.231069Z","shell.execute_reply.started":"2024-04-17T01:41:21.201436Z","shell.execute_reply":"2024-04-17T01:41:21.229984Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"torch.Size([2, 8, 128])\n","output_type":"stream"}]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self,output_dim,emb_dim,hid_dim,n_layers,dropout):\n        super().__init__()\n        self.output_dim=output_dim\n        self.hid_dim=hid_dim\n        self.n_layers=n_layers\n        self.embedding=nn.Embedding(output_dim,emb_dim)\n        \n        self.rnn=nn.LSTM(emb_dim,hid_dim,n_layers,dropout=dropout)\n        self.fc_out=nn.Linear(hid_dim,output_dim)\n        self.dropout=nn.Dropout(dropout)\n    def forward(self,input,hidden,cell):\n        ## input(batch,) 单个时间步数据\n        input=input.unsqueeze(0)\n        embedded=self.dropout(self.embedding(input))\n        output,(hidden,cell)=self.rnn(embedded,(hidden,cell))\n        ## output(batch_size,output_dim)\n        ## hidden(n_layers,batch_size,hidden_dim)\n        \n        prediction=self.fc_out(output.squeeze(0))\n        \n        return prediction,hidden,cell\n    \ndecoder=Decoder(1000,100,128,2,0.5)\ntest_input=torch.ones(8,dtype=torch.long)\nprediction,hidden,cell=decoder(test_input,hidden,cell)\nprint(prediction.shape,hidden.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:41:23.294407Z","iopub.execute_input":"2024-04-17T01:41:23.294773Z","iopub.status.idle":"2024-04-17T01:41:23.321697Z","shell.execute_reply.started":"2024-04-17T01:41:23.294747Z","shell.execute_reply":"2024-04-17T01:41:23.320508Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"torch.Size([8, 1000]) torch.Size([2, 8, 128])\n","output_type":"stream"}]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self,\n                 input_word_count,output_word_count,encode_dim,\n                 decode_dim,hidden_dim,n_layers,encode_dropout,decode_dropout,device\n                ):\n        super().__init__()\n        self.encoder=Encoder(input_word_count,encode_dim,hidden_dim,n_layers,encode_dropout)\n        self.decoder=Decoder(output_word_count,decode_dim,hidden_dim,n_layers,decode_dropout)\n        self.device=device\n        \n    def forward(self,en,zh,teacher_forcing_ratio=1):\n        if zh is not None:\n            batch_size=zh.shape[1]\n            zh_len=zh.shape[0]#时间步\n            zh_vocab_size=self.decoder.output_dim\n            ## 存放输出结果\n            outputs=torch.zeros(zh_len,batch_size,zh_vocab_size).to(self.device)\n            \n            ## encoder输出作为decoder第一个隐藏层输入\n            hidden,cell=self.encoder(en)\n            input=zh[0,:]\n            for t in range(1,zh_len):\n                output,hidden,cell=self.decoder(input,hidden,cell)\n                outputs[t]=output\n                ## 以一定概率使用techer_force\n                teacher_force=random.random()<teacher_forcing_ratio\n                top1=output.argmax(1)\n                input=zh[t] if teacher_force else top1\n        else:\n            batch_size=en.shape[1]\n            zh_vocab_size=self.decoder.output_dim\n            \n            l=[]\n            hidden,cell=self.encoder(en)\n            input=en[0,:]\n            while True:## 直到输出结果为结束符才停止\n                output,hidden,cell=self.decoder(input,hidden,cell)\n                l.append(output)\n                top1=output.argmax(1)\n                if top1==1 or len(l)>50:\n                    return l\n                input=top1\n                \n        return outputs\nimport numpy as np\ntest_input=torch.LongTensor(np.random.randint(1,1000,size=(15,1)))\nseq2seq=Seq2Seq(1000,1000,100,100,128,128,0.5,0.5,test_input.device)\noutput_list=seq2seq(test_input,None)\nlen(output_list),output_list[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:42:33.075646Z","iopub.execute_input":"2024-04-17T01:42:33.076548Z","iopub.status.idle":"2024-04-17T01:42:36.052325Z","shell.execute_reply.started":"2024-04-17T01:42:33.076511Z","shell.execute_reply":"2024-04-17T01:42:36.051342Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(51, torch.Size([1, 1000]))"},"metadata":{}}]},{"cell_type":"code","source":"source_word_count=len(en_wl)\ntarget_word_count=len(zh_wl)\nencode_dim=50\ndecode_dim=50\nhidden_dim=64\nn_layers=1\n\nencode_dropout=0.5\ndecode_dropout=0.5\ndevice=torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\nmodel=Seq2Seq(\n    source_word_count,target_word_count,encode_dim,decode_dim,hidden_dim,\n    n_layers,encode_dropout,decode_dropout,device\n).to(device)\ndef init_weight(m):\n    if isinstance(m,nn.Linear):\n            nn.init.xavier_normal_(m.weight)\n            nn.init.constant_(m.bias,0)\n    elif isinstance(m,nn.BatchNorm1d):\n        nn.init.constant_(m.weight,1)\n        nn.init.constant_(m.bias,0)\nmodel.apply(init_weight)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T02:10:07.169145Z","iopub.execute_input":"2024-04-17T02:10:07.169984Z","iopub.status.idle":"2024-04-17T02:10:07.197878Z","shell.execute_reply.started":"2024-04-17T02:10:07.169948Z","shell.execute_reply":"2024-04-17T02:10:07.196855Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(12635, 50)\n    (rnn): LSTM(50, 64, dropout=0.5)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(3002, 50)\n    (rnn): LSTM(50, 64, dropout=0.5)\n    (fc_out): Linear(in_features=64, out_features=3002, bias=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from torch import optim\noptimizer=optim.Adam(model.parameters(),lr=5e-4)\ncriterion=nn.CrossEntropyLoss(ignore_index=pad_id)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T02:10:12.875684Z","iopub.execute_input":"2024-04-17T02:10:12.876102Z","iopub.status.idle":"2024-04-17T02:10:12.882064Z","shell.execute_reply.started":"2024-04-17T02:10:12.876068Z","shell.execute_reply":"2024-04-17T02:10:12.881049Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef train(model,data_loader,optimizer,criterion,clip):\n    model.train()\n    epoch_loss=0\n    for i,batch in enumerate(tqdm(data_loader)):\n        source=batch[0].to(device)\n        target=batch[1].to(device)\n        optimizer.zero_grad()\n        output=model(source,target)\n        \n        output_dim=output.shape[-1]#词表大小\n        output=output[1:].view(-1,output_dim)\n        target=target[1:].reshape(-1)\n        loss=criterion(output,target)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n        optimizer.step()\n        epoch_loss+=loss.item()\n    return epoch_loss/len(data_loader)\n\ndef evaluate(model,data_loader,criterion):\n    model.eval()\n    epoch_loss=0\n    for i,batch in enumerate(data_loader):\n        source=batch[0].to(device)\n        target=batch[1].to(device)\n        with torch.no_grad():\n            output=model(source,target,0)#不用Teacher Forcing\n        output_dim=output.shape[-1]\n        output=output[1:].view(-1,output_dim)\n        target=target[1:].reshape(-1)\n        loss=criterion(output,target)\n        epoch_loss+=loss.item()\n    return epoch_loss/len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T01:51:54.160659Z","iopub.execute_input":"2024-04-17T01:51:54.161438Z","iopub.status.idle":"2024-04-17T01:51:54.172687Z","shell.execute_reply.started":"2024-04-17T01:51:54.161403Z","shell.execute_reply":"2024-04-17T01:51:54.171442Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"import math\nimport time\n\nepochs=10\nclip=1\nbest_valid_loss=float('inf')\nfor epoch in range(epochs):\n    train_loss=train(model,train_data_loader,optimizer,criterion,clip)\n    valid_loss=evaluate(model,test_data_loader,criterion)\n    if valid_loss<best_valid_loss:\n        best_valid_loss=valid_loss\n        torch.save(model.state_dict(),'tutl-model.pt')\n    print(f'Train loss: {train_loss:.3f} {math.exp(train_loss):7.3f}',)\n    print(f'Valid loss: {valid_loss:.3f} {math.exp(valid_loss):7.3f}',)\n    sample=translate('what is your name')\n    print(f'epoch: {epoch} sample:{sample}')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T02:10:15.163100Z","iopub.execute_input":"2024-04-17T02:10:15.163498Z","iopub.status.idle":"2024-04-17T02:15:32.815025Z","shell.execute_reply.started":"2024-04-17T02:10:15.163467Z","shell.execute_reply":"2024-04-17T02:15:32.813268Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"100%|██████████| 428/428 [00:39<00:00, 10.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 6.224 504.899\nValid loss: 6.041 420.466\nepoch: 0 sample: 的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 428/428 [00:40<00:00, 10.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 5.820 336.815\nValid loss: 6.098 445.149\nepoch: 1 sample:我们的的 我的 我的的 我的 我们的的 我的的 我的的 我的的 我的的 我的的 我的的 我的的 我的的\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 428/428 [00:39<00:00, 10.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 5.675 291.482\nValid loss: 6.185 485.522\nepoch: 2 sample:我们的的。eso\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 428/428 [00:40<00:00, 10.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 5.551 257.374\nValid loss: 6.306 547.798\nepoch: 3 sample:我们是我们是我们的人的。eso\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 428/428 [00:40<00:00, 10.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 5.453 233.391\nValid loss: 6.378 588.497\nepoch: 4 sample:我们是我们是我们的人的。eso\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 428/428 [00:40<00:00, 10.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 5.371 215.096\nValid loss: 6.453 634.785\nepoch: 5 sample:我们是我们的人的人。eso\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 428/428 [00:40<00:00, 10.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 5.295 199.420\nValid loss: 6.422 615.383\nepoch: 6 sample:我们的人们是我们的人的。eso\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 55/428 [00:05<00:40,  9.23it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[66], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m best_valid_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 8\u001b[0m     train_loss\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     valid_loss\u001b[38;5;241m=\u001b[39mevaluate(model,test_data_loader,criterion)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_loss\u001b[38;5;241m<\u001b[39mbest_valid_loss:\n","Cell \u001b[0;32mIn[50], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m      7\u001b[0m target\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m output_dim\u001b[38;5;241m=\u001b[39moutput\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;66;03m#词表大小\u001b[39;00m\n\u001b[1;32m     12\u001b[0m output\u001b[38;5;241m=\u001b[39moutput[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,output_dim)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[38], line 23\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, en, zh, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mzh[\u001b[38;5;241m0\u001b[39m,:]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,zh_len):\n\u001b[0;32m---> 23\u001b[0m     output,hidden,cell\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     outputs[t]\u001b[38;5;241m=\u001b[39moutput\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m## 以一定概率使用techer_force\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[36], line 16\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, input, hidden, cell)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m embedded\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(\u001b[38;5;28minput\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m output,(hidden,cell)\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m## output(batch_size,output_dim)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m## hidden(n_layers,batch_size,hidden_dim)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m prediction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"def translate(en_sentence):\n    words=[]\n    for word in en_sentence.strip().split(' '):\n        words.append(word.replace('.','').replace(',','').lower())\n    ids=[0]\n    for w in words:\n        ids.append(en2id[w])\n    ids.append(1)\n    source=torch.tensor(ids).unsqueeze(0).swapaxes(0,1).to(device)\n    model.eval()\n    with torch.no_grad():\n        output=model(source,None,0)\n    target=[]\n    for x in output:\n        target.append(zh_wl[x.argmax(1).cpu().item()])\n    return ''.join(target)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-17T02:15:40.319761Z","iopub.execute_input":"2024-04-17T02:15:40.320582Z","iopub.status.idle":"2024-04-17T02:15:40.329781Z","shell.execute_reply.started":"2024-04-17T02:15:40.320541Z","shell.execute_reply":"2024-04-17T02:15:40.328547Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model=Seq2Seq(\n    source_word_count,target_word_count,encode_dim,decode_dim,hidden_dim,\n    n_layers,encode_dropout,decode_dropout,device\n).to(device)\nmodel.load_state_dict(torch.load('tutl-model.pt'))\nresult=translate('what is your name')\nresult","metadata":{"execution":{"iopub.status.busy":"2024-04-17T02:15:42.483698Z","iopub.execute_input":"2024-04-17T02:15:42.484114Z","iopub.status.idle":"2024-04-17T02:15:42.538617Z","shell.execute_reply.started":"2024-04-17T02:15:42.484081Z","shell.execute_reply":"2024-04-17T02:15:42.537588Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"' 的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的'"},"metadata":{}}]},{"cell_type":"code","source":"result=translate('Sequence to Sequence Learning with Neural Networks')\nresult","metadata":{"execution":{"iopub.status.busy":"2024-04-17T02:15:44.643007Z","iopub.execute_input":"2024-04-17T02:15:44.643686Z","iopub.status.idle":"2024-04-17T02:15:44.675972Z","shell.execute_reply.started":"2024-04-17T02:15:44.643651Z","shell.execute_reply":"2024-04-17T02:15:44.674924Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"'                                                   '"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}